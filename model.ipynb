{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from \"./data/udacity/driving_log.csv\"...\n",
      "./data/udacity/\n",
      "Loading data from \"./data/t2_forward/driving_log.csv\"...\n",
      "./data/t2_forward/\n",
      "Loading data from \"./data/t2_backwards/driving_log.csv\"...\n",
      "./data/t2_backwards/\n",
      "---------------\n",
      "Printing a sample line:\n",
      "\tcenter: IMG/center_2016_12_01_13_30_48_287.jpg\n",
      "\tleft:  IMG/left_2016_12_01_13_30_48_287.jpg\n",
      "\tright:  IMG/right_2016_12_01_13_30_48_287.jpg\n",
      "\tangle: 0\n",
      "\tthrottle: 0\n",
      "\tbreak: 0\n",
      "\tspeed: 22.14829\n",
      "---------------\n",
      "Number of images is 13271.\n",
      "Number of filenames is 39813.\n",
      "Number of labels is 39813.\n",
      "Shape of X after cleaning is (21634, 160, 320, 3)\n",
      "Number of y after cleaning is 21634\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-8f1e987b80b7>:386: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"generate_training_data_from_memory\" failed type inference due to: Untyped global name 'shuffle': cannot determine Numba type of <class 'function'>\n",
      "\n",
      "File \"<ipython-input-1-8f1e987b80b7>\", line 396:\n",
      "def generate_training_data_from_memory(data_orig, labels_orig, batch_size=256, validation_flag=False, debug=False):\n",
      "    <source elided>\n",
      "    labels = np.copy(labels_orig)\n",
      "    data, labels = shuffle(data, labels)\n",
      "    ^\n",
      "\n",
      "  @jit\n",
      "/usr/local/lib/python3.7/dist-packages/numba/compiler.py:725: NumbaWarning: Function \"generate_training_data_from_memory\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"<ipython-input-1-8f1e987b80b7>\", line 387:\n",
      "@jit\n",
      "def generate_training_data_from_memory(data_orig, labels_orig, batch_size=256, validation_flag=False, debug=False):\n",
      "^\n",
      "\n",
      "  self.func_ir.loc))\n",
      "/usr/local/lib/python3.7/dist-packages/numba/compiler.py:734: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"<ipython-input-1-8f1e987b80b7>\", line 387:\n",
      "@jit\n",
      "def generate_training_data_from_memory(data_orig, labels_orig, batch_size=256, validation_flag=False, debug=False):\n",
      "^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of labels: 21634\n",
      "Batch size: 1024\n",
      "# valid samples: 8\n",
      "# per epoch: 33\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making model:\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cropping2d_1 (Cropping2D)    (None, 70, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 70, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 33, 158, 24)       1824      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 33, 158, 24)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 15, 77, 36)        21636     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 15, 77, 36)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 6, 37, 48)         43248     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 6, 37, 48)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 35, 64)         27712     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 35, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 2, 33, 64)         36928     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 2, 33, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4224)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               422500    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 559,419\n",
      "Trainable params: 559,419\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "33/33 [==============================] - 165s 5s/step - loss: 0.2946 - val_loss: 0.1347\n",
      "Epoch 2/20\n",
      "33/33 [==============================] - 162s 5s/step - loss: 0.1724 - val_loss: 0.1251\n",
      "Epoch 3/20\n",
      "33/33 [==============================] - 178s 5s/step - loss: 0.1599 - val_loss: 0.1219\n",
      "Epoch 4/20\n",
      "33/33 [==============================] - 167s 5s/step - loss: 0.1518 - val_loss: 0.1220\n",
      "Epoch 5/20\n",
      "33/33 [==============================] - 161s 5s/step - loss: 0.1495 - val_loss: 0.1204\n",
      "Epoch 6/20\n",
      "33/33 [==============================] - 155s 5s/step - loss: 0.1412 - val_loss: 0.1184\n",
      "Epoch 7/20\n",
      "33/33 [==============================] - 172s 5s/step - loss: 0.1395 - val_loss: 0.1169\n",
      "Epoch 8/20\n",
      "33/33 [==============================] - 164s 5s/step - loss: 0.1367 - val_loss: 0.1087\n",
      "Epoch 9/20\n",
      "33/33 [==============================] - 174s 5s/step - loss: 0.1311 - val_loss: 0.1034\n",
      "Epoch 10/20\n",
      "33/33 [==============================] - 168s 5s/step - loss: 0.1314 - val_loss: 0.1086\n",
      "Epoch 11/20\n",
      "33/33 [==============================] - 156s 5s/step - loss: 0.1304 - val_loss: 0.1092\n",
      "Epoch 12/20\n",
      "33/33 [==============================] - 153s 5s/step - loss: 0.1269 - val_loss: 0.1077\n",
      "Epoch 13/20\n",
      "33/33 [==============================] - 167s 5s/step - loss: 0.1258 - val_loss: 0.1000\n",
      "Epoch 14/20\n",
      "33/33 [==============================] - 167s 5s/step - loss: 0.1238 - val_loss: 0.0992\n",
      "Epoch 15/20\n",
      "33/33 [==============================] - 163s 5s/step - loss: 0.1212 - val_loss: 0.0992\n",
      "Epoch 16/20\n",
      "33/33 [==============================] - 171s 5s/step - loss: 0.1252 - val_loss: 0.0988\n",
      "Epoch 17/20\n",
      "33/33 [==============================] - 163s 5s/step - loss: 0.1227 - val_loss: 0.1044\n",
      "Epoch 18/20\n",
      "33/33 [==============================] - 172s 5s/step - loss: 0.1225 - val_loss: 0.1006\n",
      "Epoch 19/20\n",
      "33/33 [==============================] - 156s 5s/step - loss: 0.1205 - val_loss: 0.0972\n",
      "Epoch 20/20\n",
      "12/33 [=========>....................] - ETA: 1:34 - loss: 0.1207"
     ]
    }
   ],
   "source": [
    "# global parameters\n",
    "angle_correction = 0.2\n",
    "validation_split = 0.2\n",
    "batch_size = 1024\n",
    "model_debug = False # makes a simple model for debug\n",
    "udacity_data = False\n",
    "loading_model = False\n",
    "debug_cleaning = False\n",
    "augment_data = False\n",
    "\n",
    "if loading_model:\n",
    "    model_name = 'model.h5' # trained for 20 epochs\n",
    "\n",
    "# imports\n",
    "import os, platform, glob, csv, cv2\n",
    "import numpy as np\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D, Conv2D, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "from numba import jit\n",
    "device_name = sys.argv[1]  # Choose device from cmd line. Options: gpu or cpu\n",
    "if device_name == \"gpu\":\n",
    "    device_name = \"/gpu:0\"\n",
    "else:\n",
    "    device_name = \"/cpu:0\"\n",
    "\n",
    "\n",
    "def print_line(line):\n",
    "    '''\n",
    "    prints a sample line from csv\n",
    "    for debugging purposes\n",
    "    '''\n",
    "    print(\"-\"*15)\n",
    "    print(\"Printing a sample line:\")\n",
    "    for n, e in zip(lines_headers, line):\n",
    "        print(\"\\t{}: {}\".format(n, e))\n",
    "    print(\"-\"*15)\n",
    "\n",
    "#@jit\n",
    "def read_sim_logs(csv_paths):\n",
    "    \"\"\"\n",
    "    Reads each `.csv` file and stores the image file paths and measurement values to a list of dictionaries.\n",
    "    :param csv_paths: list of file paths to CSV files created by the simulator.\n",
    "    :return: list of dictionaries containing image files and measurements from the simulator at each sample.\n",
    "    \"\"\"\n",
    "    log_file_name = 'driving_log.csv'\n",
    "    \n",
    "    lines = []\n",
    "    labels = []\n",
    "    filenames = []\n",
    "    if not isinstance(csv_paths, list):\n",
    "        csv_paths = [csv_paths]\n",
    "    for i_path, path in enumerate(csv_paths):\n",
    "        csv_file_path = os.path.join(path, log_file_name)\n",
    "        print('Loading data from \"{}\"...'.format(csv_file_path))\n",
    "        img_path = path +\"IMG/\"\n",
    "        print(path)\n",
    "        with open(csv_file_path, 'rt') as f:\n",
    "            reader = csv.reader(f, delimiter=',')\n",
    "            for line in reader:\n",
    "                if line is None:\n",
    "                    # empty line\n",
    "                    continue\n",
    "                lines.append(line)\n",
    "                \n",
    "                center_image_path = os.path.join(img_path,  line[0].split('/')[-1])\n",
    "                left_image_path = os.path.join(img_path,  line[1].split('/')[-1])\n",
    "                right_image_path = os.path.join(img_path,  line[2].split('/')[-1])\n",
    "\n",
    "                center_angle = float(line[3])\n",
    "                left_angle = center_angle + angle_correction\n",
    "                right_angle = center_angle - angle_correction\n",
    "\n",
    "                labels.extend([center_angle, left_angle, right_angle])\n",
    "                filenames.extend([center_image_path, left_image_path, right_image_path])\n",
    "    return lines, filenames, labels\n",
    "\n",
    "\n",
    "def get_image(log_path, path_to_imgs):\n",
    "    '''\n",
    "    this routine returns an image by appending filename from log_path\n",
    "    to the images directory from path_to_imgs\n",
    "    '''\n",
    "    image_path = get_image_path(log_path, path_to_imgs)\n",
    "    # cv2 reads to BGR\n",
    "    return cv2.imread(image_path)\n",
    "\n",
    "def normalize_pixels(pixel_value):\n",
    "    '''\n",
    "    normalizes pixel values to have zero mean and SD of 1\n",
    "    '''\n",
    "    result = pixel_value / 255.0 - 0.5\n",
    "    return result\n",
    "\n",
    "\n",
    "    \n",
    "def clean_data(data, labels, depth=0, n_bins=20, debug=False):\n",
    "    '''\n",
    "    this routine removes data in overrepresented bins in a histogram of steering angles\n",
    "    depth paratemeter tells what is the target number of examples in each bin\n",
    "    depth of 0 means all bins should have at most as many elements as the second largest bin\n",
    "    depth of 1 means all bins should have at most as many elements as the third largest bin etc.\n",
    "    returns modified images and labels\n",
    "    ---\n",
    "    superceded by clean_filenames_labels which is a generator and works faster\n",
    "    by not storing actual data in memory\n",
    "    '''\n",
    "    (counts, bins, _) = plt.hist(labels, bins=np.linspace(-1,1,n_bins), label='hst')\n",
    "    \n",
    "    target_size = int(sorted(counts, reverse=True)[1 + depth])\n",
    "    if debug: print(\"Target bin count:\", target_size)\n",
    "    if debug: print(\"-\"*15)\n",
    "    \n",
    "    all_indices_to_remove = []\n",
    "    \n",
    "    for pos, count in enumerate(counts):\n",
    "        if debug: print(\"Position:\", pos)\n",
    "        if debug: print(\"Count:\", count)\n",
    "        if count > target_size:\n",
    "            if debug: print(\"Not alright, need to remove some.\")\n",
    "            lower_bound = bins[pos]\n",
    "            upper_bound = bins[pos + 1]\n",
    "            if debug: print(\"Lower:\", lower_bound)\n",
    "            if debug: print(\"Upper:\", upper_bound)\n",
    "            all_indices = np.where((labels > lower_bound) & (labels < upper_bound))[0]\n",
    "            n_to_remove = len(all_indices) - target_size\n",
    "            if debug: print(\"Need to remove:\", n_to_remove)\n",
    "            indices_to_remove = np.random.choice(all_indices, size = n_to_remove, replace=False)\n",
    "            if debug: print(\"All indices before:\", len(all_indices_to_remove))\n",
    "            all_indices_to_remove.extend(indices_to_remove)\n",
    "            if debug: print(\"All indices after:\", len(all_indices_to_remove))\n",
    "        else:\n",
    "            if debug: print(\"Alright, alright, alright!\")\n",
    "            continue\n",
    "        if debug: print(\"-\"*15)\n",
    "\n",
    "    labels_new = np.delete(labels, all_indices_to_remove, axis=0)\n",
    "    data_new = np.delete(data, all_indices_to_remove, axis=0)\n",
    "    return data_new, labels_new\n",
    "\n",
    "def clean_filenames_labels(filenames, labels, depth=0, n_bins=20, debug=False):\n",
    "    '''\n",
    "    this routine removes filenames and labels in overrepresented bins in a histogram of steering angles\n",
    "    depth paratemeter tells what is the target number of examples in each bin\n",
    "    depth of 0 means all bins should have at most as many elements as the second largest bin\n",
    "    depth of 1 means all bins should have at most as many elements as the third largest bin etc.\n",
    "    returns modified filenames and labels\n",
    "    \n",
    "    '''\n",
    "    if debug: print(\"*\"*30) \n",
    "    if debug: print(\"clean_filenames_labels, befor:{}\".format(len(labels)))\n",
    "    \n",
    "    (counts, bins, _) = plt.hist(labels, bins=np.linspace(-1,1,n_bins), label='hst')\n",
    "   \n",
    "    \n",
    "    target_size = int(sorted(counts, reverse=True)[1 + depth])\n",
    "    if debug: print(\"Target bin count:\", target_size)\n",
    "    if debug: print(\"-\"*15)\n",
    "    \n",
    "    all_indices_to_remove = []\n",
    "    \n",
    "    for pos, count in enumerate(counts):\n",
    "        if debug: print(\"Position:\", pos)\n",
    "        if debug: print(\"Count:\", count)\n",
    "        if count > target_size:\n",
    "            if debug: print(\"Not alright, need to remove some.\")\n",
    "            lower_bound = bins[pos]\n",
    "            upper_bound = bins[pos + 1]\n",
    "            if debug: print(\"Lower:\", lower_bound)\n",
    "            if debug: print(\"Upper:\", upper_bound)\n",
    "            all_indices = np.where((labels > lower_bound) & (labels < upper_bound))[0]\n",
    "            n_to_remove = len(all_indices) - target_size\n",
    "            if debug: print(\"Need to remove:\", n_to_remove)\n",
    "            indices_to_remove = np.random.choice(all_indices, size = n_to_remove, replace=False)\n",
    "            if debug: print(\"All indices before:\", len(all_indices_to_remove))\n",
    "            all_indices_to_remove.extend(indices_to_remove)\n",
    "            if debug: print(\"All indices after:\", len(all_indices_to_remove))\n",
    "        else:\n",
    "            if debug: print(\"[McConaughey voice] Alright, alright, alright!\")\n",
    "            continue\n",
    "        if debug: print(\"-\"*15)\n",
    "\n",
    "    labels_new = np.delete(labels, all_indices_to_remove, axis=0)\n",
    "    filenames_new = np.delete(filenames, all_indices_to_remove, axis=0)\n",
    "    \n",
    "    if debug: print(\"*\"*30) \n",
    "    if debug: print(\"clean_filenames_labels, After:{}\".format(len(labels_new)))\n",
    "    return filenames_new, labels_new \n",
    "\n",
    "def augment_filenames_labels(filenames, labels, depth=0, n_bins=20, debug=False):\n",
    "    '''\n",
    "    this routine removes filenames and labels in overrepresented bins in a histogram of steering angles\n",
    "    depth paratemeter tells what is the target number of examples in each bin\n",
    "    depth of 0 means all bins should have at most as many elements as the second largest bin\n",
    "    depth of 1 means all bins should have at most as many elements as the third largest bin etc.\n",
    "    returns modified filenames and labels\n",
    "    \n",
    "    '''\n",
    "    if debug: print(\"*\"*30) \n",
    "    if debug: print(\"augment_filenames_labels, befor:{}\".format(len(labels)))\n",
    "        \n",
    "    (counts, bins, _) = plt.hist(labels, bins=np.linspace(-1,1,n_bins), label='hst')\n",
    "    plt.show()\n",
    "    \n",
    "    target_size = int(sorted(counts, reverse=True)[1 + depth])\n",
    "    if debug: print(\"Target bin count:\", target_size)\n",
    "    if debug: print(\"-\"*15)\n",
    "    \n",
    "    add_filenames = []\n",
    "    add_lables = []\n",
    "    \n",
    "    for pos, count in enumerate(counts):\n",
    "        if debug: print(\"Position:\", pos)\n",
    "        if debug: print(\"Count:\", count)\n",
    "        if count > target_size:\n",
    "            if debug: print(\"Alright, alright, alright!\")\n",
    "            continue\n",
    "        else:\n",
    "            if debug: print(\"Not alright, need to augment some.\")\n",
    "            lower_bound = bins[pos]\n",
    "            upper_bound = bins[pos + 1]\n",
    "            if debug: print(\"Lower:\", lower_bound)\n",
    "            if debug: print(\"Upper:\", upper_bound)\n",
    "            all_indices = np.where((labels > lower_bound) & (labels < upper_bound))[0]\n",
    "            n_to_add = int(target_size - count)\n",
    "            if debug: print(\"n_to_add:\", n_to_add)\n",
    "            \n",
    "            \n",
    "            for i in range(n_to_add):\n",
    "                choice = int(np.random.choice(all_indices,1))\n",
    "                add_filenames.append(filenames[choice])\n",
    "                add_lables.append(labels[choice])\n",
    "            \n",
    "        if debug: print(\"-\"*15)\n",
    "    \n",
    "    print(\"add_filenames:{} num:{}\".format(add_filenames[0], len(add_filenames)))\n",
    "    print(\"add_lables:{} num:{}\".format(add_lables[0], len(add_lables)))\n",
    "          \n",
    "            \n",
    "    filenames.extend(add_filenames);\n",
    "    labels.extend(add_lables);\n",
    "    \n",
    "    \n",
    "    if debug: print(\"*\"*30) \n",
    "    if debug: print(\"augment_filenames_labels, After:{}\".format(len(labels)))\n",
    "    return filenames, labels\n",
    "\n",
    "\n",
    "def make_clean_data(filenames, labels):\n",
    "    '''\n",
    "    returns an array of filtered images stored in memory\n",
    "    to be fed into custom data generator\n",
    "    '''\n",
    "    X = []\n",
    "    for f in filenames:\n",
    "        image = cv2.imread(f)\n",
    "        X.append(image)\n",
    "    X = np.array(X)\n",
    "    print(\"Shape of X after cleaning is\", X.shape)\n",
    "    print(\"Number of y after cleaning is\", len(labels))\n",
    "    print()\n",
    "    \n",
    "    return X, labels\n",
    "\n",
    "\n",
    "def make_model(act='elu', d=0.5, debug=False):\n",
    "    '''\n",
    "    nVidia end-to-end driving model\n",
    "    1) custom activation and dropout\n",
    "    2) custom preprocessing layers\n",
    "    '''\n",
    "    model = Sequential()\n",
    "    model.add(Cropping2D(cropping=((65, 25), (0, 0)), input_shape=(160, 320, 3)))\n",
    "    model.add(Lambda(normalize_pixels, output_shape=(70, 320, 3)))\n",
    "    if debug:\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1))\n",
    "        return model\n",
    "    model.add(Conv2D(24, (5,5), strides=(2,2), activation=act))\n",
    "    model.add(Dropout(d))\n",
    "    model.add(Conv2D(36, (5,5), strides=(2,2), activation=act))\n",
    "    model.add(Dropout(d))\n",
    "    model.add(Conv2D(48, (5,5), strides=(2,2), activation=act))\n",
    "    model.add(Dropout(d))\n",
    "    model.add(Conv2D(64, (3,3), activation=act))\n",
    "    model.add(Dropout(d))\n",
    "    model.add(Conv2D(64, (3,3), activation=act))\n",
    "    model.add(Dropout(d))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation=act))\n",
    "    model.add(Dropout(d))\n",
    "    model.add(Dense(50, activation=act))\n",
    "    model.add(Dropout(d))\n",
    "    model.add(Dense(10, activation=act))\n",
    "    model.add(Dense(1))\n",
    "    return model\n",
    "\n",
    "\n",
    "def preprocess_image(image):\n",
    "    # Gaussian blur\n",
    "    image = cv2.GaussianBlur(image, (3,3), 0)\n",
    "    # Convert to YUV\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)\n",
    "    return image\n",
    "\n",
    "\n",
    "def brighten_image(image):\n",
    "    '''\n",
    "    performs random brightening / darkening of the image\n",
    "    in order to generalize driving in different lighting\n",
    "    conditions\n",
    "    '''\n",
    "    value = np.random.randint(-28, 28)\n",
    "    # the mask prevents values from being outside (0,255)\n",
    "    if value > 0:\n",
    "        mask = (image[:,:,0] + value) > 255 \n",
    "    if value <= 0:\n",
    "        mask = (image[:,:,0] + value) < 0\n",
    "    image[:,:,0] += np.where(mask, 0, value)\n",
    "    return image\n",
    "\n",
    "\n",
    "def shadow_image(image):\n",
    "    '''\n",
    "    random shadow to make the model drive on\n",
    "    roads with random shadows\n",
    "    shadow is random region:\n",
    "        - full height\n",
    "        - left or right portion of image\n",
    "    shadow area will be 20%-40% darker\n",
    "    '''\n",
    "    height, width = image.shape[0:2]\n",
    "    # random horizontal line\n",
    "    mid = np.random.randint(0, width)\n",
    "    # image is in YUV\n",
    "    # factor darkens 1st channel (brightness)\n",
    "    factor = np.random.uniform(0.6,0.8)\n",
    "    # random shadow on the left or on the right of image\n",
    "    if np.random.rand() > .5:\n",
    "        image[:, 0:mid, 0] *= factor\n",
    "    else:\n",
    "        image[:, mid:width, 0] *= factor\n",
    "    return image\n",
    "\n",
    "\n",
    "def shift_horizon(image):\n",
    "    '''\n",
    "    randomly shift horizon to simulate\n",
    "    driving in areas with hills\n",
    "    this transform will move horizon\n",
    "    vertically  up or down \n",
    "    for up to 1/8 of height\n",
    "    '''\n",
    "    height, width = image.shape[0:2]\n",
    "    # horizon value (calculated empirically)\n",
    "    horizon = 0.4 * height\n",
    "    v_shift = np.random.randint(- height / 8, height / 8)\n",
    "    pts1 = np.float32([[0, horizon], [width, horizon], [0, height], [width, height]])\n",
    "    pts2 = np.float32([[0, horizon + v_shift], [width, horizon + v_shift], [0, height], [width, height]])\n",
    "    transform_matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "    new_img = cv2.warpPerspective(image, transform_matrix, (width, height) , borderMode=cv2.BORDER_REPLICATE)\n",
    "    return image\n",
    "\n",
    "def augment_image(image, label, proba=0.5):\n",
    "    ''' \n",
    "    method for adding random distortion to dataset images, including random brightness adjust, and a random\n",
    "    vertical shift of the horizon position\n",
    "    '''\n",
    "    new_img = image.astype(float)\n",
    "    # 1) randomly flip image horizontally and reverse label\n",
    "    if np.random.rand() > proba:\n",
    "        new_img = cv2.flip(new_img, 1)\n",
    "        label = -label\n",
    "    # 2) random brightness\n",
    "    new_img = brighten_image(new_img)\n",
    "    # 3) random shadow\n",
    "    new_img = shadow_image(new_img)\n",
    "    # 4) random horizon shift\n",
    "    new_img = shift_horizon(new_img)\n",
    "    return new_img.astype(np.uint8), label\n",
    "\n",
    "@jit\n",
    "def generate_training_data_from_memory(data_orig, labels_orig, batch_size=256, validation_flag=False, debug=False):\n",
    "    '''\n",
    "    this is a generator that yields data from numpy array in memory\n",
    "    and performs preprocessing and augmentation on the fly,\n",
    "    without storing all augmented data in memory\n",
    "    if validation_flag is True, no augmentation is performed\n",
    "    '''\n",
    "    data = np.copy(data_orig)\n",
    "    labels = np.copy(labels_orig)\n",
    "    data, labels = shuffle(data, labels)\n",
    "    if debug:\n",
    "        original_image = data[0]\n",
    "        preprocessed_image = preprocess_image(original_image)\n",
    "        augmented_image = augment_image(preprocessed_image, labels[0])[0]\n",
    "        yield (cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB), \n",
    "               cv2.cvtColor(preprocessed_image, cv2.COLOR_YUV2RGB), \n",
    "               cv2.cvtColor(augmented_image, cv2.COLOR_YUV2RGB), \n",
    "               labels[0])\n",
    "    X, y = ([], [])\n",
    "    while True:\n",
    "        for i in range(len(labels)):\n",
    "            image = data[i]\n",
    "            label = labels[i]\n",
    "            image = preprocess_image(image)\n",
    "            if not validation_flag:\n",
    "                image, label = augment_image(image, label)\n",
    "            X.append(image)\n",
    "            y.append(label)\n",
    "            if len(X) == batch_size:\n",
    "                yield (np.array(X), np.array(y))\n",
    "                X, y = ([], [])\n",
    "                data, labels = shuffle(data, labels)\n",
    "                \n",
    "def report_images(save=False):\n",
    "    '''\n",
    "    this function plots and saves sample images for the report\n",
    "    '''\n",
    "    gen = generate_training_data_from_memory(X_clean, labels, batch_size=batch_size, debug=True)\n",
    "    img1, img2, img3, lbl = next(gen)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(img1)\n",
    "    if save: fig.savefig('images/01_original.png', bbox_inches='tight')\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(img2)\n",
    "    if save: fig.savefig('images/02_preprocessed.png', bbox_inches='tight')\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(img3)\n",
    "    if save: fig.savefig('images/03_augmented.png', bbox_inches='tight')\n",
    "    \n",
    "    img4 = img3[65:135,:,:]\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(img4)\n",
    "    if save: fig.savefig('images/04_cropped.png', bbox_inches='tight')\n",
    "    \n",
    "    img5 = normalize_pixels(img4)\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(img5)\n",
    "    if save: fig.savefig('images/05_normalized.png', bbox_inches='tight')\n",
    "            \n",
    "\n",
    "lines_headers = [\n",
    "    'center',\n",
    "    'left',\n",
    "    'right',\n",
    "    'angle',\n",
    "    'throttle',\n",
    "    'break',\n",
    "    'speed'\n",
    "]\n",
    "\n",
    "\n",
    "simulation_logs = ['./data/udacity/', \n",
    "                   './data/t2_forward/',\n",
    "                   './data/t2_backwards/']\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------------------- #\n",
    "#               BELOW IS TRAIN CODE ITSELF                #\n",
    "# ------------------------------------------------------- #\n",
    "\n",
    "# make filenames and labels for using in generating batches\n",
    "lines, filenames, labels = read_sim_logs(simulation_logs)\n",
    "\n",
    "print_line(lines[0])\n",
    "\n",
    "# Full images on Linux GPU machine (for full training)\n",
    "nb_imgs = len(lines)\n",
    "print('Number of images is {}.'.format(nb_imgs))\n",
    "print('Number of filenames is {}.'.format(len(filenames)))\n",
    "print('Number of labels is {}.'.format(len(labels)))\n",
    "\n",
    "\n",
    "\n",
    "if augment_data:\n",
    "    filenames, labels = augment_filenames_labels(filenames, labels, depth=2, debug=False)\n",
    "    print('after augment_file...')\n",
    "    print('Number of filenames is {}.'.format(len(filenames)))\n",
    "    print('Number of labels is {}.'.format(len(labels)))\n",
    "\n",
    "# remove overrepresented labels and filenames\n",
    "filenames, labels = clean_filenames_labels(filenames, labels, depth=2, debug=debug_cleaning)\n",
    "\n",
    "\n",
    "\n",
    "# local data (stores in memory to be used in generator)\n",
    "X_clean, labels_clean = make_clean_data(filenames, labels)\n",
    "\n",
    "\n",
    "# training, validation and testing generators\n",
    "train_gen = generate_training_data_from_memory(X_clean, labels, batch_size=batch_size, validation_flag=False)\n",
    "valid_gen = generate_training_data_from_memory(X_clean, labels, batch_size=batch_size, validation_flag=True)\n",
    "test_gen = generate_training_data_from_memory(X_clean, labels, batch_size=batch_size, validation_flag=True)\n",
    "\n",
    "# number of samples for validation and epoch should be multiple of batch size\n",
    "number_valid_steps = int(validation_split * len(labels_clean) * 2) // batch_size\n",
    "steps_per_epoch = int((1 - validation_split) * len(labels_clean) * 2) // batch_size\n",
    "print(\"# of labels:\", len(labels))\n",
    "print(\"Batch size:\", batch_size)\n",
    "print(\"# valid samples:\", number_valid_steps)\n",
    "print(\"# per epoch:\", steps_per_epoch)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# check histogram of the clean data\n",
    "(n, bins, patches) = plt.hist(labels, bins=np.linspace(-1,1,20), label='hst')\n",
    "plt.show()\n",
    "\n",
    "# --------------------------------------------------------\n",
    "\n",
    "if not loading_model:\n",
    "    print(\"Making model:\")\n",
    "    model = make_model(debug=model_debug)\n",
    "    model.compile(loss = 'mse', optimizer = 'adam')\n",
    "    model.summary()\n",
    "else:\n",
    "    print(\"Loading model: \", model_name)\n",
    "    model = load_model(model_name)\n",
    "    model.summary()\n",
    "\n",
    "\n",
    "# ------------------------------------------------------- #\n",
    "#       TRAINING  AND SAVING THE MODEL                    #\n",
    "# ------------------------------------------------------- #\n",
    "\n",
    "model.fit_generator(train_gen, \n",
    "                    epochs=20,\n",
    "                    validation_data=valid_gen, \n",
    "                    validation_steps=number_valid_steps, \n",
    "                    steps_per_epoch=steps_per_epoch, initial_epoch=0)\n",
    "\n",
    "model.save('model.h5')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
